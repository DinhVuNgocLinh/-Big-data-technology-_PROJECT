{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import TimestampType\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if not already set in system env vars\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk-1.8\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\\\spark-3.5.1-bin-hadoop3\"\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataCleaning\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"OnlineRetail.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Profiling, Anomaly Detection and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Check the number of colummns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  8\n",
      "Number of rows:  541909\n"
     ]
    }
   ],
   "source": [
    "# Check the number of columns and rows\n",
    "print(\"Number of columns: \", len(df.columns))\n",
    "print(\"Number of rows: \", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Abnormal 1: Check and correct Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert datatype of InvoiceDate to timestamp\n",
    "df_cleaned = df.withColumn(\"InvoiceDate\", to_timestamp(\"InvoiceDate\", \"M/d/yyyy H:mm\"))\n",
    "\n",
    "# Re-check schema\n",
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Abnormal 2: Check and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|       1454|       0|          0|        0|    135080|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in original data\n",
    "missing_values = df_cleaned.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in df_cleaned.columns\n",
    "])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Description: 1,454 --> remove since it is hard to guess the product description\n",
    "- CustomerID: 135,080 --> might keep them, change `null` value into `Unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the null values in Description\n",
    "df_cleaned = df_cleaned.filter(df_cleaned.Description.isNotNull())\n",
    "\n",
    "# Change the value in CustomerID into \"Unknown\" for null values\n",
    "df_cleaned = df_cleaned.withColumn(\"CustomerID\", when(df_cleaned.CustomerID.isNull(), \"Unknown\").otherwise(df_cleaned.CustomerID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|          0|       0|          0|        0|         0|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-check for missing values in the cleaned data\n",
    "missing_values = df_cleaned.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in df_cleaned.columns\n",
    "])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Abnormal 3: Check and handle duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  5268\n"
     ]
    }
   ],
   "source": [
    "# Check the number of duplicate rows\n",
    "duplicate_count = df_cleaned.count() - df_cleaned.dropDuplicates().count()\n",
    "print(\"Number of duplicate rows: \", duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df_cleaned = df_cleaned.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  0\n"
     ]
    }
   ],
   "source": [
    "# Re-check the number of duplicate rows\n",
    "duplicate_count = df_cleaned.count() - df_cleaned.dropDuplicates().count()\n",
    "print(\"Number of duplicate rows: \", duplicate_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 Abnormal 4: Handle negative Quantity and UnitPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the number of cancelled order:** The InvoiceNo starts with C (has negative Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of canceled orders:  9251\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|  C536825|    22617|BAKING SET SPACEB...|      -1|2010-12-02 17:27:00|     4.95|     15384|United Kingdom|\n",
      "|  C537251|    22747|POPPY'S PLAYHOUSE...|      -6|2010-12-06 10:45:00|      2.1|   Unknown|United Kingdom|\n",
      "|  C537805|    22197|SMALL POPCORN HOLDER|      -1|2010-12-08 13:18:00|     0.72|     15311|United Kingdom|\n",
      "|  C538103|    22941|CHRISTMAS LIGHTS ...|      -2|2010-12-09 15:13:00|      8.5|     17442|United Kingdom|\n",
      "|  C538768|    84378|SET OF 3 HEART CO...|     -24|2010-12-14 11:34:00|     1.25|     14829|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cancel = df_cleaned.filter(col(\"InvoiceNo\").startswith(\"C\"))\n",
    "print(\"Number of canceled orders: \", cancel.count())\n",
    "cancel.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for invalid values in Quantity and UnitPrice:**\n",
    "- Quantity < 0\n",
    "- UnitPrice < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative Quantity:  9725\n",
      "+---------+--------+\n",
      "|InvoiceNo|Quantity|\n",
      "+---------+--------+\n",
      "|  C536825|      -1|\n",
      "|  C537251|      -6|\n",
      "|  C537805|      -1|\n",
      "|  C538103|      -2|\n",
      "|  C538768|     -24|\n",
      "+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantity has negative value\n",
    "negative_Quantity = df_cleaned.filter(col(\"Quantity\") < 0).count()\n",
    "print(\"Number of negative Quantity: \", negative_Quantity)\n",
    "df_cleaned.filter(col(\"Quantity\") < 0).select(\"InvoiceNo\", \"Quantity\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative UnitPrice:  2\n",
      "+---------+---------+\n",
      "|InvoiceNo|UnitPrice|\n",
      "+---------+---------+\n",
      "|  A563186|-11062.06|\n",
      "|  A563187|-11062.06|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UnitPrice has negative value\n",
    "negative_UnitPrice = df_cleaned.filter(col(\"UnitPrice\") < 0).count()\n",
    "print(\"Number of negative UnitPrice: \", negative_UnitPrice)\n",
    "df_cleaned.filter(col(\"UnitPrice\") < 0).select(\"InvoiceNo\", \"UnitPrice\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that cancelled orders also have the negative Quantity.\n",
    "- The dataset contains 9,251 cancelled orders, while 9,725 orders have a negative quantity.\n",
    "- Therefore, in the Data Cleaning section, when we remove orders with negative quantities, we also remove the cancelled orders at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove abnormal Quantity and UnitPrice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Quantity count: 0\n",
      "Negative UnitPrice count: 0\n",
      "Number of cancelled orders:  0\n"
     ]
    }
   ],
   "source": [
    "# Filter out negative Quantity and UnitPrice\n",
    "df_cleaned = df_cleaned.filter((col(\"Quantity\") > 0) & (col(\"UnitPrice\") > 0))\n",
    "\n",
    "# Check negative Quantity and UnitPrice again\n",
    "print(\"Negative Quantity count:\", df_cleaned.filter(col(\"Quantity\") < 0).count())\n",
    "print(\"Negative UnitPrice count:\", df_cleaned.filter(col(\"UnitPrice\") < 0).count())\n",
    "\n",
    "# Check number of cancelled orders again\n",
    "cancel = df_cleaned.filter(col(\"InvoiceNo\").startswith(\"C\"))\n",
    "print(\"Number of cancelled orders: \", cancel.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6 Abnormal 5: Identify abnormal `StockCode`-`Description` pairs that are not actual products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check abnormal StockCode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------------+\n",
      "|StockCode   |Description                       |\n",
      "+------------+----------------------------------+\n",
      "|POST        |POSTAGE                           |\n",
      "|DOT         |DOTCOM POSTAGE                    |\n",
      "|gift_0001_40|Dotcomgiftshop Gift Voucher �40.00|\n",
      "|C2          |CARRIAGE                          |\n",
      "|gift_0001_30|Dotcomgiftshop Gift Voucher �30.00|\n",
      "|BANK CHARGES|Bank Charges                      |\n",
      "|M           |Manual                            |\n",
      "|AMAZONFEE   |AMAZON FEE                        |\n",
      "|gift_0001_50|Dotcomgiftshop Gift Voucher �50.00|\n",
      "|gift_0001_20|Dotcomgiftshop Gift Voucher �20.00|\n",
      "|gift_0001_10|Dotcomgiftshop Gift Voucher �10.00|\n",
      "|S           |SAMPLES                           |\n",
      "|B           |Adjust bad debt                   |\n",
      "+------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "excluded_stockcodes = [\"POST\", \"DOT\", \"M\", \"C2\", \"BANK CHARGES\",\"S\", \"B\", \"AMAZONFEE\",\n",
    "                       \"gift_0001_10\", \"gift_0001_20\",\"gift_0001_30\",\"gift_0001_40\",\"gift_0001_50\"]\n",
    "\n",
    "# Identify rows with exclued StockCode\n",
    "df_excluded = df_cleaned.filter(col(\"StockCode\").isin(excluded_stockcodes))\n",
    "\n",
    "# Show distinct excluded StockCode - Description pairs\n",
    "df_excluded.select(\"StockCode\", \"Description\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle abnormal StockCode and Description pairs that are not actual products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.filter(~col(\"StockCode\").isin(excluded_stockcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|StockCode|Description|\n",
      "+---------+-----------+\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-check the abnormal stock code\n",
    "df_excluded = df_cleaned.filter(col(\"StockCode\").isin(excluded_stockcodes))\n",
    "df_excluded.select(\"StockCode\", \"Description\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Data cleaning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before cleaning: 541909\n"
     ]
    }
   ],
   "source": [
    "# The number of rows before cleaning\n",
    "rows_before_cleaning = df.count()\n",
    "print(f\"Number of rows before cleaning: {rows_before_cleaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning: 522541\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows after cleaning\n",
    "rows_after_cleaning = df_cleaned.count()\n",
    "print(f\"Number of rows after cleaning: {rows_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: date (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "|   536384|    84755|COLOUR GLASS T-LI...|      48| 2010-12-01|     0.65|     18074|United Kingdom|\n",
      "|   536385|    22168|ORGANISER WOOD AN...|       2| 2010-12-01|      8.5|     17420|United Kingdom|\n",
      "|   536399|    22632|HAND WARMER RED P...|       6| 2010-12-01|     1.85|     17850|United Kingdom|\n",
      "|   536401|    22767|TRIPLE PHOTO FRAM...|       2| 2010-12-01|     9.95|     15862|United Kingdom|\n",
      "|   536423|    22632|HAND WARMER RED R...|      12| 2010-12-01|      2.1|     18085|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert InvoiceDate data type to DateType\n",
    "df_fe = df_cleaned.withColumn(\"InvoiceDate\", to_date(col(\"InvoiceDate\"), \"M/d/yyyy H:mm\"))\n",
    "df_fe.printSchema()\n",
    "df_fe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2011, 12, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the max date of the dataset\n",
    "max_date = df_fe.agg(max(\"InvoiceDate\")).collect()[0][0]\n",
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|CustomerID|Recency|\n",
      "+----------+-------+\n",
      "|     16250|    261|\n",
      "|     15574|    177|\n",
      "|     15555|     12|\n",
      "|     15271|      7|\n",
      "|     17757|      1|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate recency\n",
    "recency_df = df_fe.groupBy(\"CustomerID\").agg(\n",
    "    datediff(lit(max_date), max(\"InvoiceDate\")).alias(\"Recency\")\n",
    ")\n",
    "recency_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|Frequency|\n",
      "+----------+---------+\n",
      "|     15574|        4|\n",
      "|     15555|       16|\n",
      "|     16250|        2|\n",
      "|     15271|       15|\n",
      "|     17686|        7|\n",
      "+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate frequency (number of transactions per customer)\n",
    "frequency_df = df_fe.groupBy(\"CustomerID\").agg(\n",
    "    countDistinct(\"InvoiceNo\").alias(\"Frequency\")\n",
    ")\n",
    "frequency_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|CustomerID|Monetary|\n",
      "+----------+--------+\n",
      "|     15574|  675.64|\n",
      "|     15555| 4791.87|\n",
      "|     15271| 2493.34|\n",
      "|     17686| 5739.46|\n",
      "|     17714|   153.0|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Monetary (Total money spent by customer)\n",
    "monetary_df = df_fe.withColumn(\"TotalPrice\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n",
    "    .groupBy(\"CustomerID\") \\\n",
    "    .agg(round(sum(\"TotalPrice\"), 3).alias(\"Monetary\"))\n",
    "monetary_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+\n",
      "|CustomerID|Recency|Frequency|Monetary|\n",
      "+----------+-------+---------+--------+\n",
      "|     15574|    177|        4|  675.64|\n",
      "|     15555|     12|       16| 4791.87|\n",
      "|     16250|    261|        2|  389.44|\n",
      "|     15271|      7|       15| 2493.34|\n",
      "|     17686|      7|        7| 5739.46|\n",
      "+----------+-------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join all RFM features\n",
    "dfs = [recency_df, frequency_df, monetary_df]\n",
    "rfm_df = reduce(lambda df1, df2: df1.join(df2, \"CustomerID\"), dfs)\n",
    "rfm_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+\n",
      "|     Mean_Recency|   Mean_Frequency|    Mean_Monetary|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|92.20530565167243|4.561245674740484|2363.834342099192|\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average of Recency, Frequency, and Monetary\n",
    "rfm_df.select(\n",
    "    mean(\"Recency\").alias(\"Mean_Recency\"),\n",
    "    mean(\"Frequency\").alias(\"Mean_Frequency\"),\n",
    "    mean(\"Monetary\").alias(\"Mean_Monetary\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the mean recency, I chose 95 days as the threshold for labeling churn.\n",
    "However, customers who haven’t returned for over 95 days but have high frequency (i.e., they’re loyal) shouldn’t be classified as churned based on recency alone.\n",
    "Therefore, I also used the mean frequency, setting frequency = 7 as a second threshold to more accurately determine whether a customer is churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|     15574|    177|        4|  675.64|    1|\n",
      "|     15555|     12|       16| 4791.87|    0|\n",
      "|     16250|    261|        2|  389.44|    1|\n",
      "|     15271|      7|       15| 2493.34|    0|\n",
      "|     17686|      7|        7| 5739.46|    0|\n",
      "|     13865|     58|        4|  501.56|    0|\n",
      "|     17714|    320|        1|   153.0|    1|\n",
      "|     14157|     19|        2|  424.89|    0|\n",
      "|     13610|     12|        7| 1082.33|    0|\n",
      "|     16320|    172|        2| 1038.46|    1|\n",
      "|     12394|     63|        2| 1080.48|    0|\n",
      "|     13282|     18|        3| 1132.14|    0|\n",
      "|     13772|     33|        3| 1122.63|    0|\n",
      "|     13192|     95|        2|  911.94|    0|\n",
      "|     17427|     71|        1|   100.8|    0|\n",
      "|     14887|     79|        1|  1862.0|    0|\n",
      "|     17506|     75|        1|   302.2|    0|\n",
      "|     18130|     15|        3| 1059.39|    0|\n",
      "|     15634|     17|        1|  243.55|    0|\n",
      "|     15269|     23|        1|   408.8|    0|\n",
      "+----------+-------+---------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define thresholds based on the mean values\n",
    "recency_threshold = 95\n",
    "frequency_threshold = 7\n",
    "\n",
    "# Create a new column 'Churn' based on the thresholds\n",
    "rfm_df = rfm_df.withColumn(\n",
    "    \"Churn\",\n",
    "    when((col(\"Recency\") > recency_threshold) & (col(\"Frequency\") <= frequency_threshold), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame with Churn column\n",
    "rfm_df.select(\"CustomerID\", \"Recency\", \"Frequency\", \"Monetary\", \"Churn\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Dataframe**\n",
    "- If you want to work with timestamp (yyyy-M-d H:mm:ss) data, please use the code: [df_cleaned.join()]\n",
    "- If you want to work with date (only yyyy=M-d), please change the below code:[df_cleaned.join()] --> [df_fe.join()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+-------------------+---------+--------------+-----+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|       Country|Churn|\n",
      "+----------+---------+---------+--------------------+--------+-------------------+---------+--------------+-----+\n",
      "|     12431|   536389|   35004G|SET OF 3 GOLD FLY...|       4|2010-12-01 10:03:00|     6.35|     Australia|    0|\n",
      "|     12431|   536389|    21791|VINTAGE HEADS AND...|      12|2010-12-01 10:03:00|     1.25|     Australia|    0|\n",
      "|     12433|   536532|    22551|PLASTERS IN TIN S...|      24|2010-12-01 13:24:00|     1.65|        Norway|    0|\n",
      "|     12433|   536532|    21980|PACK OF 12 RED RE...|      48|2010-12-01 13:24:00|     0.29|        Norway|    0|\n",
      "|     12433|   536532|    22544|MINI JIGSAW SPACEBOY|      24|2010-12-01 13:24:00|     0.42|        Norway|    0|\n",
      "|     12433|   536532|    22198|LARGE POPCORN HOL...|      48|2010-12-01 13:24:00|     1.65|        Norway|    0|\n",
      "|     12433|   536532|    22554|PLASTERS IN TIN W...|      24|2010-12-01 13:24:00|     1.65|        Norway|    0|\n",
      "|     12583|   536370|    21883|    STARS GIFT TAPE |      24|2010-12-01 08:45:00|     0.65|        France|    0|\n",
      "|     12583|   536370|    22629| SPACEBOY LUNCH BOX |      24|2010-12-01 08:45:00|     1.95|        France|    0|\n",
      "|     12662|   536527|    20713|      JUMBO BAG OWLS|      10|2010-12-01 13:04:00|     1.95|       Germany|    0|\n",
      "|     12738|   536840|    21977|PACK OF 60 PINK P...|      24|2010-12-02 18:27:00|     0.55|       Germany|    1|\n",
      "|     12838|   536415|    22900| SET 2 TEA TOWELS...|       3|2010-12-01 11:57:00|     2.95|United Kingdom|    0|\n",
      "|     12838|   536415|    22321|BIRD DECORATION R...|      12|2010-12-01 11:57:00|     0.85|United Kingdom|    0|\n",
      "|     12838|   536415|    22750|FELTCRAFT PRINCES...|       2|2010-12-01 11:57:00|     3.75|United Kingdom|    0|\n",
      "|     12838|   536415|    22149|FELTCRAFT 6 FLOWE...|       4|2010-12-01 11:57:00|      2.1|United Kingdom|    0|\n",
      "|     12868|   536523|    21259|VICTORIAN SEWING ...|       2|2010-12-01 12:50:00|     5.95|United Kingdom|    1|\n",
      "|     12868|   536523|    22227|HANGING HEART MIR...|      24|2010-12-01 12:50:00|     0.65|United Kingdom|    1|\n",
      "|     12868|   536523|    22111|SCOTTIE DOG HOT W...|       3|2010-12-01 12:50:00|     4.95|United Kingdom|    1|\n",
      "|     12921|   536561|    22750|FELTCRAFT PRINCES...|       4|2010-12-01 15:06:00|     3.75|United Kingdom|    0|\n",
      "|     12947|   536582|    22634|CHILDS BREAKFAST ...|       2|2010-12-01 16:21:00|     9.95|United Kingdom|    1|\n",
      "+----------+---------+---------+--------------------+--------+-------------------+---------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join churn label into transaction-level cleaned data\n",
    "final_df = df_cleaned.join(rfm_df.select(\"CustomerID\", \"Churn\"), on=\"CustomerID\", how=\"left\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further steps after my parts, I got a few instruction for each role of the type of dataframe\n",
    "- df: original raw dataframe\n",
    "- df_cleaned: dataframe after data cleaning in part 3\n",
    "- df_fe : dataframe where the InvoiceDate converted into Date formula.\n",
    "- rfm_df :  The RFM dataframe with columns [CustomerID, Recency, Frequency, Monetary, Churn]\n",
    "- final_df (optional) : use this if you prefer working directly with the cleaned transactional data (df_cleaned) rather than the aggregated RFM data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
